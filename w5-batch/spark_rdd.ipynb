{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resilient Distributed Datasets in Spark\n",
    "\n",
    "It turns out DataFrames are implemented on top of RDDs.\n",
    "\n",
    "- dataframes have schema\n",
    "- RDD is simply a collection of objects\n",
    "\n",
    "## Map and reduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/23 15:10:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../data/taxi_ingest_data/parts/green/*/*')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.rdd` returns the underlying RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 12, 33, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 12, 38, 42), store_and_fwd_flag='N', RatecodeID=1, PULocationID=24, DOLocationID=41, passenger_count=1, trip_distance=0.9300000071525574, fare_amount=6.0, extra=0.0, mta_tax=0.5, tip_amount=1.3600000143051147, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=8.15999984741211, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 0, 7, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 0, 9, 47), store_and_fwd_flag='N', RatecodeID=1, PULocationID=193, DOLocationID=193, passenger_count=1, trip_distance=0.4699999988079071, fare_amount=4.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=5.300000190734863, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 12, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 12, 28), store_and_fwd_flag=None, RatecodeID=None, PULocationID=33, DOLocationID=49, passenger_count=None, trip_distance=2.1500000953674316, fare_amount=20.93000030517578, extra=2.75, mta_tax=0.0, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=23.979999542236328, payment_type=None, trip_type=None, congestion_surcharge=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd.take(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Row` object is also returned if we `.take` from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 12, 33, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 12, 38, 42), store_and_fwd_flag='N', RatecodeID=1, PULocationID=24, DOLocationID=41, passenger_count=1, trip_distance=0.9300000071525574, fare_amount=6.0, extra=0.0, mta_tax=0.5, tip_amount=1.3600000143051147, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=8.15999984741211, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 0, 7, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 0, 9, 47), store_and_fwd_flag='N', RatecodeID=1, PULocationID=193, DOLocationID=193, passenger_count=1, trip_distance=0.4699999988079071, fare_amount=4.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=5.300000190734863, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 12, 7), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 12, 28), store_and_fwd_flag=None, RatecodeID=None, PULocationID=33, DOLocationID=49, passenger_count=None, trip_distance=2.1500000953674316, fare_amount=20.93000030517578, extra=2.75, mta_tax=0.0, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.30000001192092896, total_amount=23.979999542236328, payment_type=None, trip_type=None, congestion_surcharge=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lpep_pickup_datetime', 'PULocationID', 'total_amount']\n",
    "rdd_green = df_green \\\n",
    "                .select(*cols) \\\n",
    "                .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(year=2020, month=1, day=1)\n",
    "def filter_datetime(row):\n",
    "    \"\"\"\n",
    "    pyspark.RDD.filter callable\n",
    "    only accepts row as argument\n",
    "    \"\"\"\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_groupby(row):\n",
    "    # assigning our keys\n",
    "    # truncate to datetime to hour\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    # key becomes a tuple\n",
    "    key = (hour, zone)\n",
    "\n",
    "    # assigning values \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    # value's also a tuple so that we have a 1:1 key: value relation\n",
    "    value = (amount, count)\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 23, 12, 0), 24), (8.15999984741211, 1)),\n",
       " ((datetime.datetime(2020, 1, 23, 0, 0), 193), (5.300000190734863, 1)),\n",
       " ((datetime.datetime(2020, 1, 29, 12, 0), 33), (23.979999542236328, 1)),\n",
       " ((datetime.datetime(2020, 1, 3, 15, 0), 224), (12.569999694824219, 1)),\n",
       " ((datetime.datetime(2020, 1, 10, 6, 0), 74), (10.5600004196167, 1)),\n",
       " ((datetime.datetime(2020, 1, 27, 18, 0), 226), (20.299999237060547, 1)),\n",
       " ((datetime.datetime(2020, 1, 27, 7, 0), 74), (35.689998626708984, 1)),\n",
       " ((datetime.datetime(2020, 1, 3, 16, 0), 75), (8.760000228881836, 1)),\n",
       " ((datetime.datetime(2020, 1, 4, 19, 0), 129), (36.060001373291016, 1)),\n",
       " ((datetime.datetime(2020, 1, 6, 15, 0), 61), (4.300000190734863, 1))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_green \\\n",
    "    .filter(filter_datetime) \\\n",
    "    .map(prepare_for_groupby) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-zoomcamp-ofDTZRjf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5353673437182399eff36f4c16ed56ea0c7acdfe0ac221ac5d31504a99f322a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
