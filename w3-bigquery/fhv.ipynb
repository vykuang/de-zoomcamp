{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHV retrieval prototype\n",
    "\n",
    "source: https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet, for all 2019\n",
    "\n",
    "Can partition the url to\n",
    "\n",
    "- base: https://d37ci6vzurychx.cloudfront.net/trip-data/\n",
    "- filename: `<taxi_type>_tripdata_<yyyy>-<mm>.parqet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from logging import getLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger(name=\"fhv.ipynb\")\n",
    "def fetch(dataset_url: str) -> pd.DataFrame:\n",
    "    \"\"\"Read taxi data in parquet format from web and \n",
    "    return as dataframe\n",
    "\n",
    "    Set retries=3 to get around web traffic jitters\n",
    "    \"\"\"\n",
    "    # logger = get_run_logger()\n",
    "    df = pd.read_parquet(dataset_url, engine='pyarrow')\n",
    "    logger.info(f\"{len(df)} rows loaded from url\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "urls = defaultdict(str)\n",
    "urls[0] = \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet\"\n",
    "# df = fetch(urls[0])\n",
    "# print(f'num records in fhv jan: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01 02:51:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>2019-01-01 00:54:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>2019-01-01 00:54:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:19:00</td>\n",
       "      <td>2019-01-01 00:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:27:00</td>\n",
       "      <td>2019-01-01 00:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00001 2019-01-01 00:30:00 2019-01-01 02:51:55           NaN   \n",
       "1               B00001 2019-01-01 00:45:00 2019-01-01 00:54:49           NaN   \n",
       "2               B00001 2019-01-01 00:15:00 2019-01-01 00:54:52           NaN   \n",
       "3               B00008 2019-01-01 00:19:00 2019-01-01 00:39:00           NaN   \n",
       "4               B00008 2019-01-01 00:27:00 2019-01-01 00:37:00           NaN   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           NaN      NaN                 B00001  \n",
       "1           NaN      NaN                 B00001  \n",
       "2           NaN      NaN                 B00001  \n",
       "3           NaN      NaN                 B00008  \n",
       "4           NaN      NaN                 B00008  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num              object\n",
       "pickup_datetime           datetime64[ns]\n",
       "dropOff_datetime          datetime64[ns]\n",
       "PUlocationID                     float64\n",
       "DOlocationID                     float64\n",
       "SR_Flag                          float64\n",
       "Affiliated_base_number            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datatypes are all a-okay. Try with `pd.io.ql.get_schema`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"fhv_taxi_data\" (\n",
      "\"dispatching_base_num\" TEXT,\n",
      "  \"pickup_datetime\" TIMESTAMP,\n",
      "  \"dropOff_datetime\" TIMESTAMP,\n",
      "  \"PUlocationID\" REAL,\n",
      "  \"DOlocationID\" REAL,\n",
      "  \"SR_Flag\" REAL,\n",
      "  \"Affiliated_base_number\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='fhv_taxi_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:08:44</td>\n",
       "      <td>2019-02-01 00:23:35</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:27:51</td>\n",
       "      <td>2019-02-01 00:32:54</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:18:30</td>\n",
       "      <td>2019-02-01 00:25:45</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:43:15</td>\n",
       "      <td>2019-02-01 00:48:29</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:01:45</td>\n",
       "      <td>2019-02-01 00:09:13</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00037 2019-02-01 00:08:44 2019-02-01 00:23:35         264.0   \n",
       "1               B00037 2019-02-01 00:27:51 2019-02-01 00:32:54         264.0   \n",
       "2               B00037 2019-02-01 00:18:30 2019-02-01 00:25:45         264.0   \n",
       "3               B00037 2019-02-01 00:43:15 2019-02-01 00:48:29         264.0   \n",
       "4               B00037 2019-02-01 00:01:45 2019-02-01 00:09:13         264.0   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0         265.0      NaN                 B00037  \n",
       "1         265.0      NaN                 B00037  \n",
       "2         265.0      NaN                 B00037  \n",
       "3         265.0      NaN                 B00037  \n",
       "4         265.0      NaN                 B00037  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_feb = Path(\"../data/taxi_ingest_data/fhv/fhv_tripdata_2019-02.parquet\")\n",
    "feb = pq.read_table(path_feb)\n",
    "# ignore the casting error:\n",
    "# pyarrow.lib.ArrowInvalid: Casting from timestamp[us] to timestamp[ns] would result in out of bounds\n",
    "df_feb = feb.to_pandas(safe=False)\n",
    "df_feb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_recs: 1707650\n",
      "weird timestamp: 1849-12-25 18:20:52.580896768\n"
     ]
    }
   ],
   "source": [
    "# but results in weird times; originally meant to be 3019-02-03 17:30:00.000000\n",
    "print(f\"num_recs: {len(df_feb)}\\nweird timestamp: {df_feb['dropOff_datetime'].min()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the values before converting to `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = pq.read_table(path_feb)\n",
    "df_feb_clean = feb.filter(\n",
    "    pc.less_equal(feb[\"dropOff_datetime\"], pa.scalar(pd.Timestamp.max))\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_recs: 1707649\n",
      "weird timestamp: 2019-02-01 00:01:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_recs: {len(df_feb_clean)}\\nweird timestamp: {df_feb_clean['dropOff_datetime'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pickup_datetime', 'dropOff_datetime'] ['dispatching_base_num', 'PUlocationID', 'DOlocationID', 'SR_Flag', 'Affiliated_base_number']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00037</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:08:44</td>\n",
       "      <td>2019-02-01 00:23:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00037</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:27:51</td>\n",
       "      <td>2019-02-01 00:32:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00037</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:18:30</td>\n",
       "      <td>2019-02-01 00:25:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:43:15</td>\n",
       "      <td>2019-02-01 00:48:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00037</td>\n",
       "      <td>2019-02-01 00:01:45</td>\n",
       "      <td>2019-02-01 00:09:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num  PUlocationID  DOlocationID  SR_Flag  \\\n",
       "0               B00037         264.0         265.0      NaN   \n",
       "1               B00037         264.0         265.0      NaN   \n",
       "2               B00037         264.0         265.0      NaN   \n",
       "3               B00037         264.0         265.0      NaN   \n",
       "4               B00037         264.0         265.0      NaN   \n",
       "\n",
       "  Affiliated_base_number     pickup_datetime    dropOff_datetime  \n",
       "0                 B00037 2019-02-01 00:08:44 2019-02-01 00:23:35  \n",
       "1                 B00037 2019-02-01 00:27:51 2019-02-01 00:32:54  \n",
       "2                 B00037 2019-02-01 00:18:30 2019-02-01 00:25:45  \n",
       "3                 B00037 2019-02-01 00:43:15 2019-02-01 00:48:29  \n",
       "4                 B00037 2019-02-01 00:01:45 2019-02-01 00:09:13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feb.column_names\n",
    "dt_cols = [col for col in feb.column_names if \"datetime\" in col]\n",
    "nondt_cols = [col for col in feb.column_names if col not in dt_cols]\n",
    "print(dt_cols, nondt_cols)\n",
    "df_feb_dts = pd.DataFrame()\n",
    "for dt_col in dt_cols:\n",
    "    feb_dt = feb.column(dt_col)\n",
    "    df_feb_dts[dt_col] = pd.to_datetime(feb_dt, errors='coerce')\n",
    "\n",
    "# print(feb_dt)\n",
    "# dts = pd.to_datetime(feb_dt, errors='coerce')\n",
    "df_feb = feb.select(nondt_cols).to_pandas()\n",
    "df_feb = pd.concat([df_feb, df_feb_dts], axis=1)\n",
    "df_feb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num              object\n",
       "PUlocationID                       Int32\n",
       "DOlocationID                       Int32\n",
       "SR_Flag                             Int8\n",
       "Affiliated_base_number            object\n",
       "pickup_datetime           datetime64[ns]\n",
       "dropOff_datetime          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi = df_feb\n",
    "df_taxi['SR_Flag'] = df_taxi['SR_Flag'].astype('Int8', errors='ignore')\n",
    "id_cols = [col for col in df_taxi.columns if \"locationID\" in col]\n",
    "df_taxi[id_cols] = df_taxi[id_cols].astype('Int32', errors='ignore')\n",
    "df_taxi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUlocationID  DOlocationID  SR_Flag\n",
       "0           264           265     <NA>\n",
       "1           264           265     <NA>\n",
       "2           264           265     <NA>\n",
       "3           264           265     <NA>\n",
       "4           264           265     <NA>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi[id_cols + ['SR_Flag']].head().astype('Int32', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = pd.Series([None, 1, 2])\n",
    "foo.astype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num: string\n",
       "pickup_datetime: timestamp[us]\n",
       "dropOff_datetime: timestamp[us]\n",
       "PUlocationID: double\n",
       "DOlocationID: double\n",
       "SR_Flag: null\n",
       "Affiliated_base_number: string\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dec = Path(\"../data/taxi_ingest_data/fhv/fhv_tripdata_2019-12.parquet\")\n",
    "dec = pq.read_table(path_dec)\n",
    "dec.schema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`table.cast(target_schema)` allows us to set the datatypes before sending to GCS for bigquery external table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num: string\n",
       "pickup_datetime: timestamp[us]\n",
       "dropOff_datetime: timestamp[us]\n",
       "PUlocationID: int16\n",
       "DOlocationID: int16\n",
       "SR_Flag: int8\n",
       "Affiliated_base_number: string"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_schema = pa.schema([\n",
    "    ('dispatching_base_num', pa.string()),\n",
    "    ('pickup_datetime', pa.timestamp('us')),\n",
    "    ('dropOff_datetime', pa.timestamp('us')),\n",
    "    ('PUlocationID', pa.int16()),\n",
    "    ('DOlocationID', pa.int16()),\n",
    "    ('SR_Flag', pa.int8()),\n",
    "    ('Affiliated_base_number', pa.string()),\n",
    "])\n",
    "dec_typed = dec.cast(target_schema=fhv_schema)\n",
    "dec_typed.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed_parq_path = Path(\"../data/cache/fhv-2019-12.parquet\")\n",
    "pq.write_table(dec_typed, typed_parq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num              object\n",
       "pickup_datetime           datetime64[ns]\n",
       "dropOff_datetime          datetime64[ns]\n",
       "PUlocationID                     float64\n",
       "DOlocationID                     float64\n",
       "SR_Flag                          float64\n",
       "Affiliated_base_number            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_schema = {\n",
    "#     pa.int16() : pd.\n",
    "# }\n",
    "df_dec_typed = pd.read_parquet(typed_parq_path)\n",
    "df_dec_typed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num: string\n",
       "pickup_datetime: timestamp[us]\n",
       "dropOff_datetime: timestamp[us]\n",
       "PUlocationID: int16\n",
       "DOlocationID: int16\n",
       "SR_Flag: int8\n",
       "Affiliated_base_number: string"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_read = pq.read_table(typed_parq_path)\n",
    "dec_read.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fhv_tripdata_2019-02.parquet'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = Path(urls[1])\n",
    "fname = fp.name\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m month \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      5\u001b[0m dataset_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtaxi_type\u001b[39m}\u001b[39;00m\u001b[39m_tripdata_\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mmonth\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m fpath \u001b[39m=\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdata_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtaxi_type\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_file\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m local_path \u001b[39m=\u001b[39m write_local(df, fpath)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/taxi_ingest_data\"\n",
    "taxi_type = \"fhv\"\n",
    "year = 2019\n",
    "month = 1\n",
    "dataset_file = f\"{taxi_type}_tripdata_{year}-{month:02}\"\n",
    "fpath = Path(f\"{data_dir}/{taxi_type}/{dataset_file}.parquet\")\n",
    "local_path = write_local(df, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow, task\n",
    "from prefect_gcp.cloud_storage import GcsBucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def upload_gcs(block_name: str, fpath: Path) -> None:\n",
    "    \"\"\"Upload the local parquet file to GCS\"\"\"\n",
    "    gcs_block = GcsBucket.load(block_name)\n",
    "    # this will return <color>/<filename>.parquet\n",
    "    gcs_path = Path(fpath.parts[-2]) / fpath.parts[-1]\n",
    "    gcs_block.upload_from_path(from_path=fpath, to_path=gcs_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow()\n",
    "def web_gcs_parq(\n",
    "    taxi_type: str, year: int, month: int, block_name: str, data_dir: str = \"../data/cache\"\n",
    ") -> None:\n",
    "    \"\"\"Main ETL function\"\"\"\n",
    "    dataset_file = f\"{taxi_type}_tripdata_{year}-{month:02}\"\n",
    "    dataset_url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{dataset_file}.parquet\"\n",
    "\n",
    "    fpath = Path(f\"{data_dir}/{taxi_type}/{dataset_file}.parquet\")\n",
    "    if not fpath.exists():\n",
    "        df = fetch(dataset_url)\n",
    "        # df_clean = clean(df)\n",
    "        fpath = write_local(df, fpath)\n",
    "    upload_gcs(block_name, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:21.313 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'secret-turtle'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'web-gcs-parq'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:21.313 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'secret-turtle'\u001b[0m for flow\u001b[1;35m 'web-gcs-parq'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:22.640 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'secret-turtle'</span> - Created task run 'upload_gcs-bf4ea732-0' for task 'upload_gcs'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:22.640 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'secret-turtle'\u001b[0m - Created task run 'upload_gcs-bf4ea732-0' for task 'upload_gcs'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:22.644 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'secret-turtle'</span> - Executing 'upload_gcs-bf4ea732-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:22.644 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'secret-turtle'\u001b[0m - Executing 'upload_gcs-bf4ea732-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:23.285 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'upload_gcs-bf4ea732-0' - Getting bucket 'dtc_data_lake_de-zoom-83'.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:23.285 | \u001b[36mINFO\u001b[0m    | Task run 'upload_gcs-bf4ea732-0' - Getting bucket 'dtc_data_lake_de-zoom-83'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:23.361 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'upload_gcs-bf4ea732-0' - Uploading from PosixPath('../data/taxi_ingest_data/fhv/fhv_tripdata_2019-01.parquet') to the bucket 'dtc_data_lake_de-zoom-83' path 'data/fhv/fhv_tripdata_2019-01.parquet'.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:23.361 | \u001b[36mINFO\u001b[0m    | Task run 'upload_gcs-bf4ea732-0' - Uploading from PosixPath('../data/taxi_ingest_data/fhv/fhv_tripdata_2019-01.parquet') to the bucket 'dtc_data_lake_de-zoom-83' path 'data/fhv/fhv_tripdata_2019-01.parquet'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:25.014 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'upload_gcs-bf4ea732-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:25.014 | \u001b[36mINFO\u001b[0m    | Task run 'upload_gcs-bf4ea732-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:47:25.208 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'secret-turtle'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:47:25.208 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'secret-turtle'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=LiteralResult(type='literal', value=None))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_name = \"ny-taxi-gcs\"\n",
    "web_gcs_parq(taxi_type, year, month, block_name, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 12\n"
     ]
    }
   ],
   "source": [
    "mths = \"1-12\"\n",
    "a, b = list(map(int, mths.split(\"-\")))\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mths = \"12\"\n",
    "if '-' in mths:\n",
    "    a, b = list(map(int, mths.split(\"-\")))\n",
    "else:\n",
    "    a = int(mths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(a, a+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "a = b = 2\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = ['<Blob: dtc_data_lake_de-zoom-83, data/fhv/fhv_tripdata_2019-01.parquet, 1675877819813642>', '<Blob: dtc_data_lake_de-zoom-83, data/fhv/fhv_tripdata_2019-02.parquet, 1675878686204679>']\n",
    "fname = \"fhv_tripdata_2019-02.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/fhv/fhv_tripdata_2019-01.parquet,',\n",
       " 'data/fhv/fhv_tripdata_2019-02.parquet,']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [[fn for fn in blob.split() if '/' in fn][0] for blob in blobs]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present = [fname in n for n in b]\n",
    "present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-zoomcamp-ofDTZRjf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5353673437182399eff36f4c16ed56ea0c7acdfe0ac221ac5d31504a99f322a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
